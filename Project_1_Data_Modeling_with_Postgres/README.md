# Sparkify database project
Completed by Kenneth Preston

    1. Discuss the purpose of this database in the context of the startup, Sparkify, and their analytical goals.

The purpose of this database is to store data generated by Sparkify, music streaming platform. This company wants to be able to run song play analyses from their data. Currently resides in json logs and meta data stored in different locations. One goal is to have an etl pipeline to build the database tables and update with new records as they become available. Another goal is to be able to run queries on the database that the analytics team provides.

    2. State and justify your database schema design and ETL pipeline.

### Star schema 

For this database we used the star schema design. This design is simple and organizes the data around fact tables and dimension tables that help add more detail as needed when making queries. This approach helps simplify queries and allow for fast aggregations, which will work well for the use case outlined by Sparkify. 

This database is denormalized into songplays fact table and dimension tables to elaborate on details for users, songs, artists, and time music is played.

##### songplays
songplays includes an automatically generate primary key serialized as new entries are added. This helps allow the database to automatically create unique ids and avoid any manual increments in the etl process. This fact table includes the start time timestamp, user id, level, song id, artist id, session id, location, and user agent. from this table all dimension tables can be joined on as needed.

##### users
Users includes an integer primary key that matches to the user id in the songplays table. This users table provides details on user first and last name, gender and level.

##### songs
The songs table has a song id that matches to songplays table that is a character string. This table includes the song title, artist id, year, and duration of the song.

##### artists
The artists table has a id that links it to both the songplays table and the song table. In addition to the id, this table provides the artist name, location, latitude, and longitude.

##### time
The time table provides a breakdown of the timestamp provided in the songplays table that is more human readable. The timestamp is broken down into the corresponding hour, day, week, month, year, and weekday. This breakdown is helpful when trying to analyze sparkify's data by time.


### ETL pipeline

The etl pipeline crawls sparkify's directory and extracts information from the json files generated for song data and log data and writes the corresponding information into the tables outlined above. 

More specifically here are the main steps:

##### process song file
*   Open song file with pandas read_json function, specifiying data typ as 'series' and then creating a dataframe of the data and transposing the table.
*   Next the first row of this table has the song id, title, artist id, year, and duraction extracted. This extracted data is then inserted into the songs table.
*   The first row of this table is again references ad the artist id, artistis name, artist location, latitude, and longitude is extracted. This is inserted into the artist table
    
##### process log file
*   First we open the log file with pandas' read_json function with the option lines=True. 
*   We then filter on only records that show 'NextSong' as the action (i.e. page is equal to 'NextSong')
*   the timestamp data in column ts is converted to a datetime with the units specified as ms for millisecond.
*   Next the data for time is extracted from this datetime object. From this object the timestamp itself, the hour, day, week, year, and weekday is inserted into the time table in the database
*   Following this we extract the user id, first name, last name, gender, and level of the user and write the data into the user table.
*   The last step is to now extract the data fro the songplay table. This is a bit more tricky as we need to extract all the data from the log data we need along with the song id and artist id from the song data processed earlier.
*   To allow this we first query the songs and artists table matching by song title, artist name, and song duration that we have in the log file to get the correct artist and song ids from song and artist table we created earlier. We upload this data (along with the start_time timestamp, user id, level, session id, location, and user agent) to the songplay table.


    3. [Optional] Provide example queries and results for song play analysis.
    

### Example Query

##### Example 1: Query by day of week

'select weekday, count(songplay_id) from songplays join time on time.start_time = songplays.start_time group by weekday order by weekday'

| weekday  | count  |
|---|---|
|  0 | 1014  |  
|  1 | 1071  |   
|  2 | 1364  |  
|  3 | 1052  |   
|  4 | 1450  |  
|  5 | 628  |   
|  6 | 396  |  

This query shows the spotify team where most of there music streams occur throughout the week, which appears along wednesday (2) and friday (4), while the weekend has the lowest streams.

##### Example 2: Query usership by gender

'select gender, count(songplay_id) from songplays join users on users.user_id = songplays.user_id group by gender'

| gender  | count  |
|---|---|
|  M | 1972  |  
|  F | 5003  |   

This query shows that most of the songplays are coming from female users, at more than double that of males. This begs the question, what proportion of users are male and female to begin with?

'select gender, count(user_id) from users group by gender'

| gender  | count  |
|---|---|
| M  | 41  |
| F  | 55  |

This show that females make up a large portion of the database, but not more than double to explain the differences seen on songplay counts. We can conclude that females are more likely to be sparkify users and use the service more frequently than males.
